{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "from perlin_numpy import generate_perlin_noise_2d\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "np.random.seed(1)\n",
    "\n",
    "m = 5 # Physical observations per iteration (Default 5)\n",
    "n = 100 # Simulated observations per iteration (Default 100)\n",
    "\n",
    "# Number of observations to train the GP on before starting the active learning loop\n",
    "pretrain_n = 1\n",
    "\n",
    "# Minimum percentile to explore each iteration\n",
    "percentile = 50\n",
    "\n",
    "# Number of iterations to run the active learning loop (Default 10)\n",
    "iterations = 10\n",
    "\n",
    "# Corrective constant when calculating percentages\n",
    "laplace_alpha = 0.01\n",
    "\n",
    "# Degree of the polynomial to fit to the data\n",
    "degree = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of benchmark functions to test\n",
    "ackley = lambda X, Y: -(20 * (1 - np.exp(-0.2 * np.sqrt(0.5 * (X**2 + Y**2)))) - np.exp(0.5 * (np.cos(2 * np.pi * X) + np.cos(2 * np. pi * Y))) + np.exp(1))\n",
    "beale = lambda X, Y: -((1.5 - X + X * Y)**2 + (2.25 - X + X * Y**2)**2 + (2.625 - X + X * Y**3)**2)\n",
    "bird = lambda X, Y: -(np.sin(X) * np.exp((1 - np.cos(Y))**2) + np.cos(Y) * np.exp((1 - np.sin(X))**2) + (X - Y)**2)\n",
    "booth = lambda X, Y: -((X + 2 * Y - 7)**2 + (2 * X + Y - 5)**2)\n",
    "bukin6 = lambda X, Y: -(100 * np.sqrt(abs(Y - 0.01 * X**2)) + 0.01 * np.abs(X + 10))\n",
    "crossintray = lambda X, Y: 0.0001 * (np.abs(np.sin(X) * np.sin(Y) * np.exp(np.abs(100 - np.sqrt(X**2 + Y**2) / np.pi))) + 1)**0.1\n",
    "crownedcross = lambda X, Y: -0.0001 * (np.abs(np.sin(X) * np.sin(Y) * np.exp(np.abs(100 - np.sqrt(X**2 + Y**2) / np.pi))) + 1)**0.1\n",
    "goldsteinprice = lambda X, Y: -(1 + (X + Y + 1)**2 * (19 - 14 * X + 3 * X**2 - 14 * Y + 6 * X * Y + 3 * Y**2)) * (30 + (2 * X - 3 * Y)**2 * (18 - 32 * X + 12 * X**2 + 48 * Y - 36 * X * Y + 27 * Y**2))\n",
    "griewank = lambda X, Y: -((X**2 + Y**2) / 200 - np.cos(X) * np.cos(Y / np.sqrt(2)) + 1)\n",
    "himmelblau = lambda X, Y: -((X**2 + Y - 11)**2 + (X + Y**2 - 7)**2)\n",
    "holdertable = lambda X, Y: np.abs(np.sin(X) * np.cos(Y) * np.exp(np.abs(1 - np.sqrt(X**2 + Y**2) / np.pi)))\n",
    "leon = lambda X, Y: -(100 * (Y - X**3)**2 + (1 - X)**2)\n",
    "levi13 = lambda X, Y: -(np.sin(3 * np.pi * X)**2 + (X - 1)**2 * (1 + np.sin(3 * np.pi * Y)**2) + (Y - 1)**2 * (1 + np.sin(2 * np.pi * Y)**2))\n",
    "matyas = lambda X, Y: -(0.26 * (X**2 + Y**2) - 0.48 * X * Y)\n",
    "mccormick = lambda X, Y: -(np.sin(X + Y) + (X - Y)**2 - 1.5 * X + 2.5 * Y + 1)\n",
    "penholder = lambda X, Y: np.exp(-(np.abs(np.cos(X) * np.cos(Y) * np.exp(np.abs(1 - np.sqrt(X**2 + Y**2) / np.pi))))**-1)\n",
    "perlin = lambda X, Y: generate_perlin_noise_2d((X.shape[0], X.shape[1]), (2, 2))\n",
    "rastrigin = lambda X, Y: -(X**2 + Y**2 - 10 * np.cos(2 * np.pi * X) - 10 * np.cos(2 * np.pi * Y) + 2)\n",
    "schweffel = lambda X, Y: X * np.sin(np.sqrt(np.abs(X))) + Y * np.sin(np.sqrt(np.abs(Y)))\n",
    "sixhumpcamel = lambda X, Y: -((4 - 2.1 * X**2 + X**4 / 3) * X**2 + X * Y + (4 * Y**2 - 4) * Y**2)\n",
    "testtubeholder = lambda X, Y: 4 * np.abs(np.sin(X) * np.cos(Y) * np.exp(np.abs(np.cos((X**2 + Y**2) / 200))))\n",
    "zettl = lambda X, Y: -((X**2 + Y**2 - 2 * X)**2 + X / 4)\n",
    "\n",
    "# Added benchmark functions \n",
    "eggholder = lambda X, Y: -((Y + 47) * np.sin(np.sqrt(np.abs(Y + X / 2 + 47))) - X * np.sin(np.sqrt(np.abs(X - (Y + 47)))))\n",
    "threehumpcamel = lambda X, Y: -(2 * X**2 - 1.05 * X**4 + X**6 / 6 + X * Y + Y**2)\n",
    "\n",
    "# Dictionary of benchmark functions with their bounds\n",
    "objectives = {\n",
    "    \"ackley\": {\n",
    "        \"func\": ackley,\n",
    "        \"bounds\": [(-35, 35)] * 2\n",
    "    },\n",
    "    \"beale\": {\n",
    "        \"func\": beale,\n",
    "        \"bounds\": [(-4.5, 4.5)] * 2\n",
    "    },\n",
    "    \"bird\": {\n",
    "        \"func\": bird,\n",
    "        \"bounds\": [(-2 * np.pi, 2 * np.pi)] * 2\n",
    "    },\n",
    "    \"booth\": {\n",
    "        \"func\": booth,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"bukin6\": {\n",
    "        \"func\": bukin6,\n",
    "        \"bounds\": [(-15, 5), (-3, 3)]\n",
    "    },\n",
    "    \"crossintray\": {\n",
    "        \"func\": crossintray,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"crownedcross\": {\n",
    "        \"func\": crownedcross,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"goldsteinprice\": {\n",
    "        \"func\": goldsteinprice,\n",
    "        \"bounds\": [(-2, 2)] * 2\n",
    "    },\n",
    "    \"griewank\": {\n",
    "        \"func\": griewank,\n",
    "        \"bounds\": [(-100, 100)] * 2\n",
    "    },\n",
    "    \"himmelblau\": {\n",
    "        \"func\": himmelblau,\n",
    "        \"bounds\": [(-5, 5)] * 2\n",
    "    },\n",
    "    \"holdertable\": {\n",
    "        \"func\": holdertable,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"leon\": {\n",
    "        \"func\": leon,\n",
    "        \"bounds\": [(-1.2, 1.2)] * 2\n",
    "    },\n",
    "    \"levi13\": {\n",
    "        \"func\": levi13,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"matyas\": {\n",
    "        \"func\": matyas,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"mccormick\": {\n",
    "        \"func\": mccormick,\n",
    "        \"bounds\": [(-1.5, 4), (-3, 4)]\n",
    "    },\n",
    "    \"penholder\": {\n",
    "        \"func\": penholder,\n",
    "        \"bounds\": [(-11, 11)] * 2\n",
    "    },\n",
    "    \"perlin\": {\n",
    "        \"func\": perlin,\n",
    "        \"bounds\": [(-1, 1)] * 2\n",
    "    },\n",
    "    \"rastrigin\": {\n",
    "        \"func\": rastrigin,\n",
    "        \"bounds\": [(-5.12, 5.12)] * 2\n",
    "    },\n",
    "    \"schweffel\": {\n",
    "        \"func\": schweffel,\n",
    "        \"bounds\": [(-500, 500)] * 2\n",
    "    },\n",
    "    \"sixhumpcamel\": {\n",
    "        \"func\": sixhumpcamel,\n",
    "        \"bounds\": [(-5, 5)] * 2\n",
    "    },\n",
    "    \"testtubeholder\": {\n",
    "        \"func\": testtubeholder,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"zettl\": {\n",
    "        \"func\": zettl,\n",
    "        \"bounds\": [(-5, 5)] * 2\n",
    "    },\n",
    "    \"eggholder\": {\n",
    "        \"func\": eggholder,\n",
    "        \"bounds\": [(-512, 512)] * 2\n",
    "    },\n",
    "    \"threehumpcamel\": {\n",
    "        \"func\": threehumpcamel,\n",
    "        \"bounds\": [(-5, 5)] * 2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_err = lambda n, x: np.random.normal(0, x, n)\n",
    "sys_err = lambda n, x, y, poly_model: poly_model.intercept_ + poly_model.coef_[0] * x + poly_model.coef_[1] * y + poly_model.coef_[2] * x**2 + poly_model.coef_[3] * y**2 + poly_model.coef_[4] * x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ackley\t99.865\n",
      "beale\t99.2\n",
      "bird\t93.31\n",
      "booth\t98.16\n",
      "bukin6\t98.65\n",
      "crossintray\t99.665\n",
      "crownedcross\t98.305\n",
      "goldsteinprice\t99.09\n",
      "griewank\t99.815\n",
      "himmelblau\t96.9\n",
      "holdertable\t97.6\n",
      "leon\t99.34\n",
      "levi13\t99.82\n",
      "matyas\t99.245\n",
      "mccormick\t99.73\n",
      "penholder\t98.035\n",
      "perlin\t98.26\n",
      "rastrigin\t99.785\n",
      "schweffel\t99.425\n",
      "sixhumpcamel\t99.86\n",
      "testtubeholder\t99.23\n",
      "zettl\t99.5\n",
      "eggholder\t97.23\n",
      "threehumpcamel\t99.22\n"
     ]
    }
   ],
   "source": [
    "# Silence repetitive warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Run the active learning loop for each benchmark function\n",
    "for obj in list(objectives.keys()):\n",
    "    # Get the bounds for the function\n",
    "    xy_range = objectives[obj][\"bounds\"]\n",
    "\n",
    "    # Generate the meshgrid for the function\n",
    "    X = np.arange(*xy_range[0], ((xy_range[0][1] - xy_range[0][0]) / 100))\n",
    "    Y = np.arange(*xy_range[1], ((xy_range[1][1] - xy_range[1][0]) / 100))\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = objectives[obj][\"func\"](X, Y) # Values are computed and stored in Z\n",
    "\n",
    "    # Get the range of the function\n",
    "    z_range = (np.floor(np.min(Z)) - 1, np.ceil(np.max(Z)) + 1) # Used later in interpolations\n",
    "\n",
    "    # Generate the initial training data\n",
    "    df = pd.DataFrame(np.random.randint(100, size=(pretrain_n, 2))) \n",
    "\n",
    "    # Rename the index columns\n",
    "    df.columns = [\"i\", \"j\"]\n",
    "\n",
    "    # Calculate the x, y, and z columns with some random error\n",
    "    df[\"x\"] = X[0, df[\"i\"]]\n",
    "    df[\"y\"] = Y[df[\"j\"], 0]\n",
    "    df[\"z\"] = Z[df[\"i\"], df[\"j\"]] + ran_err(pretrain_n, 0.05)\n",
    "\n",
    "    # Create a copy of the dataframe to store the simulated data\n",
    "    simul_df = df.copy()\n",
    "\n",
    "    # Fit a polynomial (model) to the (initial) data\n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    poly_features = poly_features.fit_transform(simul_df[[\"x\", \"y\"]])\n",
    "\n",
    "    # Fit a linear regression model to polynomial\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model = poly_model.fit(poly_features, simul_df[\"z\"])\n",
    "\n",
    "    # Generate some more initial training data \n",
    "    df = pd.DataFrame(np.random.randint(100, size=(m, 2)))\n",
    "\n",
    "    # Rename the index columns\n",
    "    df.columns = [\"i\", \"j\"]\n",
    "\n",
    "    # Calculate the x, y, and z columns with some random error\n",
    "    df[\"x\"] = X[0, df[\"i\"]]\n",
    "    df[\"y\"] = Y[df[\"j\"], 0]\n",
    "    df[\"z\"] = Z[df[\"i\"], df[\"j\"]] + ran_err(m, 0.05)\n",
    "\n",
    "    # Active learning loop\n",
    "    #Purpose: Iteratively improve the GP model by sampling new points based on model's predictions\n",
    "    for idx in range(1, iterations + 1):\n",
    "        # Fit a Gaussian Process to the data\n",
    "        krnl = RBF(length_scale=1) # Radial Basis Function (used for smoothness and variability of the functions that GP can model)\n",
    "        model = GaussianProcessRegressor(kernel=krnl, normalize_y=False, random_state=3, alpha=0.001) # target values are not normalized, reproducibility is ensured, noise level to omprove stability in predictions. \n",
    "\n",
    "        # Randomly sample within our function's bounds\n",
    "        tmp_df = pd.DataFrame(np.random.randint(100, size=(n, 2)))\n",
    "\n",
    "        # Rename the index columns\n",
    "        tmp_df.columns = [\"i\", \"j\"]\n",
    "\n",
    "        # Generate some simulated data (using the poly model with some systematic error)\n",
    "        tmp_df[\"x\"] = X[0, tmp_df[\"i\"]]\n",
    "        tmp_df[\"y\"] = Y[tmp_df[\"j\"], 0]\n",
    "        tmp_df[\"z\"] = sys_err(n, tmp_df[\"x\"], tmp_df[\"y\"], poly_model)\n",
    "\n",
    "        # Fit a GP to the data\n",
    "        model.fit(tmp_df[[\"x\", \"y\"]], tmp_df[\"z\"])\n",
    "\n",
    "        # Make predictions using simulated data\n",
    "        pred = model.predict(tmp_df[[\"x\", \"y\"]])\n",
    "\n",
    "        # Interpolate the predictions to the meshgrid\n",
    "        z = griddata((tmp_df[\"x\"], tmp_df[\"y\"]), pred, (X.T, Y.T), method=\"linear\", fill_value=z_range[0])\n",
    "\n",
    "        # Construct a grid of all points in the meshgrid\n",
    "        tmp_df = pd.DataFrame(list(product(range(100), range(100))), columns=[\"i\", \"j\"])\n",
    "\n",
    "        # Calculate the x, y, and z columns with some random error\n",
    "        tmp_df[\"x\"] = X[0, tmp_df[\"i\"]]\n",
    "        tmp_df[\"y\"] = Y[tmp_df[\"j\"], 0]\n",
    "        tmp_df[\"z\"] = Z[tmp_df[\"i\"], tmp_df[\"j\"]] + ran_err(10000, 0.05) # Actual function values with some random error are calculated for full grid\n",
    "\n",
    "        # Construct probability distribution for points to sample from\n",
    "        mag = z[tmp_df[\"i\"], tmp_df[\"j\"]] # Computed mag for grid points\n",
    "        p = mag - z.min()\n",
    "        p = np.where(p > np.percentile(p, percentile), p, 0) + laplace_alpha \n",
    "        p /= p.sum()\n",
    "        tmp_df = tmp_df.loc[np.random.choice(tmp_df.index, size=m, p=p, replace=False)]\n",
    "\n",
    "        # Training Data is updated to include new sampled points \n",
    "        df = pd.concat([df, tmp_df], ignore_index=True)\n",
    "\n",
    "        simul_df = pd.concat([simul_df, tmp_df], ignore_index=True)\n",
    "\n",
    "        # Refitted Polynomial Model using updated data\n",
    "        poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "        poly_features = poly_features.fit_transform(simul_df[[\"x\", \"y\"]])\n",
    "\n",
    "        poly_model = LinearRegression()\n",
    "        poly_model = poly_model.fit(poly_features, simul_df[\"z\"])\n",
    "\n",
    "    # GP model is refitted on the complete dataset\n",
    "    krnl = RBF(length_scale=1)\n",
    "    model = GaussianProcessRegressor(kernel=krnl, normalize_y=False, random_state=3, alpha=0.001)\n",
    "\n",
    "    model.fit(df[[\"x\", \"y\"]], df[\"z\"])\n",
    "\n",
    "    # Prediction for entire dataset \n",
    "    pred = model.predict(df[[\"x\", \"y\"]])\n",
    "\n",
    "    # Interpolate predictions on meshgrid\n",
    "    z = griddata((df[\"x\"], df[\"y\"]), pred, (X.T, Y.T), method=\"linear\", fill_value=(z_range[0] + 1))\n",
    "\n",
    "    # Performance is printed as the percentile score of the maximum prediction compared to the actual function values\n",
    "    print(obj, percentileofscore(Z.flatten(), Z[np.unravel_index(z.argmax(), z.shape)]), sep=\"\\t\", end=\"\\r\\n\")\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
