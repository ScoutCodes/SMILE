{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "from perlin_numpy import generate_perlin_noise_2d\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.stats import percentileofscore, norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "np.random.seed(1)\n",
    "\n",
    "m = 5 # Physical observations per iteration (Default 5)\n",
    "n = 100 # Simulated observations per iteration (Default 100)\n",
    "\n",
    "# Number of observations to train the GP on before starting the active learning loop\n",
    "pretrain_n = 1\n",
    "\n",
    "# Minimum percentile to explore each iteration\n",
    "percentile = 50\n",
    "\n",
    "# Number of iterations to run the active learning loop (Default 10)\n",
    "iterations = 10\n",
    "\n",
    "# Corrective constant when calculating percentages\n",
    "laplace_alpha = 0.01\n",
    "\n",
    "# Degree of the polynomial to fit to the data\n",
    "degree = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of benchmark functions to test\n",
    "ackley = lambda X, Y: -(20 * (1 - np.exp(-0.2 * np.sqrt(0.5 * (X**2 + Y**2)))) - np.exp(0.5 * (np.cos(2 * np.pi * X) + np.cos(2 * np. pi * Y))) + np.exp(1))\n",
    "beale = lambda X, Y: -((1.5 - X + X * Y)**2 + (2.25 - X + X * Y**2)**2 + (2.625 - X + X * Y**3)**2)\n",
    "bird = lambda X, Y: -(np.sin(X) * np.exp((1 - np.cos(Y))**2) + np.cos(Y) * np.exp((1 - np.sin(X))**2) + (X - Y)**2)\n",
    "booth = lambda X, Y: -((X + 2 * Y - 7)**2 + (2 * X + Y - 5)**2)\n",
    "bukin6 = lambda X, Y: -(100 * np.sqrt(abs(Y - 0.01 * X**2)) + 0.01 * np.abs(X + 10))\n",
    "crossintray = lambda X, Y: 0.0001 * (np.abs(np.sin(X) * np.sin(Y) * np.exp(np.abs(100 - np.sqrt(X**2 + Y**2) / np.pi))) + 1)**0.1\n",
    "crownedcross = lambda X, Y: -0.0001 * (np.abs(np.sin(X) * np.sin(Y) * np.exp(np.abs(100 - np.sqrt(X**2 + Y**2) / np.pi))) + 1)**0.1\n",
    "goldsteinprice = lambda X, Y: -(1 + (X + Y + 1)**2 * (19 - 14 * X + 3 * X**2 - 14 * Y + 6 * X * Y + 3 * Y**2)) * (30 + (2 * X - 3 * Y)**2 * (18 - 32 * X + 12 * X**2 + 48 * Y - 36 * X * Y + 27 * Y**2))\n",
    "griewank = lambda X, Y: -((X**2 + Y**2) / 200 - np.cos(X) * np.cos(Y / np.sqrt(2)) + 1)\n",
    "himmelblau = lambda X, Y: -((X**2 + Y - 11)**2 + (X + Y**2 - 7)**2)\n",
    "holdertable = lambda X, Y: np.abs(np.sin(X) * np.cos(Y) * np.exp(np.abs(1 - np.sqrt(X**2 + Y**2) / np.pi)))\n",
    "leon = lambda X, Y: -(100 * (Y - X**3)**2 + (1 - X)**2)\n",
    "levi13 = lambda X, Y: -(np.sin(3 * np.pi * X)**2 + (X - 1)**2 * (1 + np.sin(3 * np.pi * Y)**2) + (Y - 1)**2 * (1 + np.sin(2 * np.pi * Y)**2))\n",
    "matyas = lambda X, Y: -(0.26 * (X**2 + Y**2) - 0.48 * X * Y)\n",
    "mccormick = lambda X, Y: -(np.sin(X + Y) + (X - Y)**2 - 1.5 * X + 2.5 * Y + 1)\n",
    "penholder = lambda X, Y: np.exp(-(np.abs(np.cos(X) * np.cos(Y) * np.exp(np.abs(1 - np.sqrt(X**2 + Y**2) / np.pi))))**-1)\n",
    "perlin = lambda X, Y: generate_perlin_noise_2d((X.shape[0], X.shape[1]), (2, 2))\n",
    "rastrigin = lambda X, Y: -(X**2 + Y**2 - 10 * np.cos(2 * np.pi * X) - 10 * np.cos(2 * np.pi * Y) + 2)\n",
    "schweffel = lambda X, Y: X * np.sin(np.sqrt(np.abs(X))) + Y * np.sin(np.sqrt(np.abs(Y)))\n",
    "sixhumpcamel = lambda X, Y: -((4 - 2.1 * X**2 + X**4 / 3) * X**2 + X * Y + (4 * Y**2 - 4) * Y**2)\n",
    "testtubeholder = lambda X, Y: 4 * np.abs(np.sin(X) * np.cos(Y) * np.exp(np.abs(np.cos((X**2 + Y**2) / 200))))\n",
    "zettl = lambda X, Y: -((X**2 + Y**2 - 2 * X)**2 + X / 4)\n",
    "\n",
    "# Dictionary of benchmark functions with their bounds\n",
    "objectives = {\n",
    "    \"ackley\": {\n",
    "        \"func\": ackley,\n",
    "        \"bounds\": [(-35, 35)] * 2\n",
    "    },\n",
    "    \"beale\": {\n",
    "        \"func\": beale,\n",
    "        \"bounds\": [(-4.5, 4.5)] * 2\n",
    "    },\n",
    "    \"bird\": {\n",
    "        \"func\": bird,\n",
    "        \"bounds\": [(-2 * np.pi, 2 * np.pi)] * 2\n",
    "    },\n",
    "    \"booth\": {\n",
    "        \"func\": booth,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"bukin6\": {\n",
    "        \"func\": bukin6,\n",
    "        \"bounds\": [(-15, 5), (-3, 3)]\n",
    "    },\n",
    "    \"crossintray\": {\n",
    "        \"func\": crossintray,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"crownedcross\": {\n",
    "        \"func\": crownedcross,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"goldsteinprice\": {\n",
    "        \"func\": goldsteinprice,\n",
    "        \"bounds\": [(-2, 2)] * 2\n",
    "    },\n",
    "    \"griewank\": {\n",
    "        \"func\": griewank,\n",
    "        \"bounds\": [(-100, 100)] * 2\n",
    "    },\n",
    "    \"himmelblau\": {\n",
    "        \"func\": himmelblau,\n",
    "        \"bounds\": [(-5, 5)] * 2\n",
    "    },\n",
    "    \"holdertable\": {\n",
    "        \"func\": holdertable,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"leon\": {\n",
    "        \"func\": leon,\n",
    "        \"bounds\": [(-1.2, 1.2)] * 2\n",
    "    },\n",
    "    \"levi13\": {\n",
    "        \"func\": levi13,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"matyas\": {\n",
    "        \"func\": matyas,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"mccormick\": {\n",
    "        \"func\": mccormick,\n",
    "        \"bounds\": [(-1.5, 4), (-3, 4)]\n",
    "    },\n",
    "    \"penholder\": {\n",
    "        \"func\": penholder,\n",
    "        \"bounds\": [(-11, 11)] * 2\n",
    "    },\n",
    "    # \"perlin\": {\n",
    "    #     \"func\": perlin,\n",
    "    #     \"bounds\": [(-1, 1)] * 2\n",
    "    # },\n",
    "    \"rastrigin\": {\n",
    "        \"func\": rastrigin,\n",
    "        \"bounds\": [(-5.12, 5.12)] * 2\n",
    "    },\n",
    "    \"schweffel\": {\n",
    "        \"func\": schweffel,\n",
    "        \"bounds\": [(-500, 500)] * 2\n",
    "    },\n",
    "    \"sixhumpcamel\": {\n",
    "        \"func\": sixhumpcamel,\n",
    "        \"bounds\": [(-5, 5)] * 2\n",
    "    },\n",
    "    \"testtubeholder\": {\n",
    "        \"func\": testtubeholder,\n",
    "        \"bounds\": [(-10, 10)] * 2\n",
    "    },\n",
    "    \"zettl\": {\n",
    "        \"func\": zettl,\n",
    "        \"bounds\": [(-5, 5)] * 2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_err = lambda n, x: np.random.normal(0, x, n)\n",
    "sys_err = lambda n, x, y, poly_model: poly_model.intercept_ + poly_model.coef_[0] * x + poly_model.coef_[1] * y + poly_model.coef_[2] * x**2 + poly_model.coef_[3] * y**2 + poly_model.coef_[4] * x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_improvement(x, model, y_max, xi=0.01):\n",
    "    mu, sigma = model.predict(x.reshape(1, -1), return_std=True)\n",
    "    with np.errstate(divide='warn'):\n",
    "        imp = mu - y_max - xi\n",
    "        Z = imp / sigma\n",
    "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        ei[sigma == 0.0] = 0.0\n",
    "    return -ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ackley\t99.305\n",
      "beale\t76.74\n",
      "bird\t69.21\n",
      "booth\t99.49\n",
      "bukin6\t93.89\n",
      "crossintray\t98.475\n",
      "crownedcross\t97.165\n",
      "goldsteinprice\t85.08\n",
      "griewank\t89.115\n",
      "himmelblau\t81.62\n",
      "holdertable\t69.61\n",
      "leon\t85.13\n",
      "levi13\t89.77\n",
      "matyas\t97.605\n",
      "mccormick\t97.32\n",
      "penholder\t95.775\n",
      "rastrigin\t90.685\n",
      "schweffel\t98.205\n",
      "sixhumpcamel\t91.88\n",
      "testtubeholder\t28.09\n",
      "zettl\t94.91\n"
     ]
    }
   ],
   "source": [
    "# Silence repetitive warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Active learning loop\n",
    "for obj in list(objectives.keys()):\n",
    "    # Get the bounds for the function\n",
    "    xy_range = objectives[obj][\"bounds\"]\n",
    "\n",
    "    # Generate the meshgrid for the function\n",
    "    X = np.arange(*xy_range[0], ((xy_range[0][1] - xy_range[0][0]) / 100))\n",
    "    Y = np.arange(*xy_range[1], ((xy_range[1][1] - xy_range[1][0]) / 100))\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = objectives[obj][\"func\"](X, Y)\n",
    "\n",
    "    # Get the range of the function\n",
    "    z_range = (np.floor(np.min(Z)) - 1, np.ceil(np.max(Z)) + 1)\n",
    "\n",
    "    # Generate the initial training data\n",
    "    df = pd.DataFrame(np.random.randint(100, size=(pretrain_n, 2)))\n",
    "\n",
    "    # Rename the index columns\n",
    "    df.columns = [\"i\", \"j\"]\n",
    "\n",
    "    # Calculate the x, y, and z columns with some random error\n",
    "    df[\"x\"] = X[0, df[\"i\"]]\n",
    "    df[\"y\"] = Y[df[\"j\"], 0]\n",
    "    df[\"z\"] = Z[df[\"i\"], df[\"j\"]] + ran_err(pretrain_n, 0.05)\n",
    "\n",
    "    # Create a copy of the dataframe to store the simulated data\n",
    "    simul_df = df.copy()\n",
    "\n",
    "    # Fit a polynomial to the data\n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    poly_features = poly_features.fit_transform(simul_df[[\"x\", \"y\"]])\n",
    "\n",
    "    # Fit a linear regression model to polynomial\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model = poly_model.fit(poly_features, simul_df[\"z\"])\n",
    "\n",
    "    # Generate some more initial training data\n",
    "    df = pd.DataFrame(np.random.randint(100, size=(m, 2)))\n",
    "\n",
    "    # Rename the index columns\n",
    "    df.columns = [\"i\", \"j\"]\n",
    "\n",
    "    # Calculate the x, y, and z columns with some random error\n",
    "    df[\"x\"] = X[0, df[\"i\"]]\n",
    "    df[\"y\"] = Y[df[\"j\"], 0]\n",
    "    df[\"z\"] = Z[df[\"i\"], df[\"j\"]] + ran_err(m, 0.05)\n",
    "\n",
    "    for idx in range(1, iterations + 1):\n",
    "        #Fit a GP to the data\n",
    "        kernel = RBF(length_scale=1)\n",
    "        model = GaussianProcessRegressor(kernel=kernel, normalize_y=False, random_state=3, alpha=0.001)\n",
    "\n",
    "        # Randomly sample within our function's bounds\n",
    "        tmp_df = pd.DataFrame(np.random.randint(100, size=(n, 2)))\n",
    "\n",
    "        # Rename the index columns\n",
    "        tmp_df.columns = [\"i\", \"j\"]\n",
    "\n",
    "        # Generate some simulated data\n",
    "        tmp_df[\"x\"] = X[0, tmp_df[\"i\"]]\n",
    "        tmp_df[\"y\"] = Y[tmp_df[\"j\"], 0]\n",
    "        tmp_df[\"z\"] = sys_err(n, tmp_df[\"x\"], tmp_df[\"y\"], poly_model)\n",
    "\n",
    "        # Fit a GP to the data\n",
    "        model.fit(tmp_df[[\"x\", \"y\"]], tmp_df[\"z\"])\n",
    "\n",
    "        # Make predictions using simulated data\n",
    "        pred = model.predict(tmp_df[[\"x\", \"y\"]])\n",
    "        y_max = pred.max()\n",
    "\n",
    "        # Find the next sampling point using the acquisition function\n",
    "        res = minimize(fun=expected_improvement, x0=np.random.uniform(xy_range[0][0], xy_range[0][1], size=(1, 2)), \n",
    "                       bounds=xy_range, args=(model, y_max))\n",
    "        next_point = res.x\n",
    "\n",
    "        # Sample new points based on the next point\n",
    "        tmp_df = pd.DataFrame({'x': [next_point[0]], 'y': [next_point[1]], \n",
    "                               'z': [objectives[obj]['func'](next_point[0], next_point[1]) + np.random.normal(0, 0.05)]})\n",
    "\n",
    "        df = pd.concat([df, tmp_df], ignore_index=True)\n",
    "\n",
    "        simul_df = pd.concat([simul_df, tmp_df], ignore_index=True)\n",
    "\n",
    "        poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "        poly_features = poly_features.fit_transform(simul_df[[\"x\", \"y\"]])\n",
    "\n",
    "        poly_model = LinearRegression()\n",
    "        poly_model = poly_model.fit(poly_features, simul_df[\"z\"])\n",
    "\n",
    "    krnl = RBF(length_scale=1)\n",
    "    model = GaussianProcessRegressor(kernel=krnl, normalize_y=False, random_state=3, alpha=0.001)\n",
    "\n",
    "    model.fit(df[[\"x\", \"y\"]], df[\"z\"])\n",
    "\n",
    "    pred = model.predict(df[[\"x\", \"y\"]])\n",
    "\n",
    "    z = griddata((df[\"x\"], df[\"y\"]), pred, (X.T, Y.T), method=\"linear\", fill_value=(z_range[0] + 1))\n",
    "\n",
    "    print(obj, percentileofscore(Z.flatten(), Z[np.unravel_index(z.argmax(), z.shape)]), sep=\"\\t\", end=\"\\r\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
