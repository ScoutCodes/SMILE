{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skopt.space import Real, Integer\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "from scipy.stats import qmc  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maximum Principal Elastic Strain (m/m)</th>\n",
       "      <th>Total Deformation (m)</th>\n",
       "      <th>Equivalent Elastic Strain (m/m)</th>\n",
       "      <th>Sample Volume (mm³)</th>\n",
       "      <th>Strain to Deformation Ratio</th>\n",
       "      <th>Length (mm)</th>\n",
       "      <th>Breadth (mm)</th>\n",
       "      <th>Depth (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.650000e-08</td>\n",
       "      <td>1.190000e-09</td>\n",
       "      <td>2.170000e-08</td>\n",
       "      <td>16400000</td>\n",
       "      <td>13.783160</td>\n",
       "      <td>403.1</td>\n",
       "      <td>406.3</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.460000e-08</td>\n",
       "      <td>1.060000e-09</td>\n",
       "      <td>1.930000e-08</td>\n",
       "      <td>16400000</td>\n",
       "      <td>13.776398</td>\n",
       "      <td>399.9</td>\n",
       "      <td>412.5</td>\n",
       "      <td>100.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.280000e-08</td>\n",
       "      <td>9.290000e-10</td>\n",
       "      <td>1.690000e-08</td>\n",
       "      <td>16400000</td>\n",
       "      <td>13.767023</td>\n",
       "      <td>403.0</td>\n",
       "      <td>412.7</td>\n",
       "      <td>99.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.100000e-08</td>\n",
       "      <td>7.960000e-10</td>\n",
       "      <td>1.450000e-08</td>\n",
       "      <td>16400000</td>\n",
       "      <td>13.772023</td>\n",
       "      <td>397.8</td>\n",
       "      <td>412.7</td>\n",
       "      <td>99.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.170000e-09</td>\n",
       "      <td>6.630000e-10</td>\n",
       "      <td>1.210000e-08</td>\n",
       "      <td>16400000</td>\n",
       "      <td>13.830928</td>\n",
       "      <td>398.0</td>\n",
       "      <td>408.9</td>\n",
       "      <td>99.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2.920000e-09</td>\n",
       "      <td>2.120000e-10</td>\n",
       "      <td>3.860000e-09</td>\n",
       "      <td>24766722</td>\n",
       "      <td>13.770127</td>\n",
       "      <td>457.8</td>\n",
       "      <td>389.6</td>\n",
       "      <td>138.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>3.000000e-09</td>\n",
       "      <td>2.180000e-10</td>\n",
       "      <td>3.960000e-09</td>\n",
       "      <td>25490140</td>\n",
       "      <td>13.770127</td>\n",
       "      <td>397.0</td>\n",
       "      <td>445.2</td>\n",
       "      <td>145.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3.080000e-09</td>\n",
       "      <td>2.230000e-10</td>\n",
       "      <td>4.060000e-09</td>\n",
       "      <td>18053160</td>\n",
       "      <td>13.770127</td>\n",
       "      <td>375.4</td>\n",
       "      <td>418.0</td>\n",
       "      <td>115.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3.160000e-09</td>\n",
       "      <td>2.290000e-10</td>\n",
       "      <td>4.170000e-09</td>\n",
       "      <td>21779712</td>\n",
       "      <td>13.770127</td>\n",
       "      <td>382.1</td>\n",
       "      <td>413.1</td>\n",
       "      <td>137.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>3.240000e-09</td>\n",
       "      <td>2.350000e-10</td>\n",
       "      <td>4.280000e-09</td>\n",
       "      <td>22809327</td>\n",
       "      <td>13.770127</td>\n",
       "      <td>389.4</td>\n",
       "      <td>461.0</td>\n",
       "      <td>126.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Maximum Principal Elastic Strain (m/m)  Total Deformation (m)  \\\n",
       "0                             1.650000e-08           1.190000e-09   \n",
       "1                             1.460000e-08           1.060000e-09   \n",
       "2                             1.280000e-08           9.290000e-10   \n",
       "3                             1.100000e-08           7.960000e-10   \n",
       "4                             9.170000e-09           6.630000e-10   \n",
       "..                                     ...                    ...   \n",
       "65                            2.920000e-09           2.120000e-10   \n",
       "66                            3.000000e-09           2.180000e-10   \n",
       "67                            3.080000e-09           2.230000e-10   \n",
       "68                            3.160000e-09           2.290000e-10   \n",
       "69                            3.240000e-09           2.350000e-10   \n",
       "\n",
       "    Equivalent Elastic Strain (m/m)  Sample Volume (mm³)  \\\n",
       "0                      2.170000e-08             16400000   \n",
       "1                      1.930000e-08             16400000   \n",
       "2                      1.690000e-08             16400000   \n",
       "3                      1.450000e-08             16400000   \n",
       "4                      1.210000e-08             16400000   \n",
       "..                              ...                  ...   \n",
       "65                     3.860000e-09             24766722   \n",
       "66                     3.960000e-09             25490140   \n",
       "67                     4.060000e-09             18053160   \n",
       "68                     4.170000e-09             21779712   \n",
       "69                     4.280000e-09             22809327   \n",
       "\n",
       "    Strain to Deformation Ratio  Length (mm)  Breadth (mm)  Depth (mm)  \n",
       "0                     13.783160        403.1         406.3       101.0  \n",
       "1                     13.776398        399.9         412.5       100.9  \n",
       "2                     13.767023        403.0         412.7        99.5  \n",
       "3                     13.772023        397.8         412.7        99.7  \n",
       "4                     13.830928        398.0         408.9        99.1  \n",
       "..                          ...          ...           ...         ...  \n",
       "65                    13.770127        457.8         389.6       138.2  \n",
       "66                    13.770127        397.0         445.2       145.6  \n",
       "67                    13.770127        375.4         418.0       115.9  \n",
       "68                    13.770127        382.1         413.1       137.5  \n",
       "69                    13.770127        389.4         461.0       126.8  \n",
       "\n",
       "[70 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Updated_Drone_Data_Modified.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Maximum Principal Elastic Strain (m/m)  Total Deformation (m)  \\\n",
      "0                                   165.0           1.190000e-09   \n",
      "1                                   146.0           1.060000e-09   \n",
      "2                                   128.0           9.290000e-10   \n",
      "3                                   110.0           7.960000e-10   \n",
      "4                                    91.7           6.630000e-10   \n",
      "\n",
      "   Equivalent Elastic Strain (m/m)  Sample Volume (mm³)  \\\n",
      "0                     2.170000e-08             16400000   \n",
      "1                     1.930000e-08             16400000   \n",
      "2                     1.690000e-08             16400000   \n",
      "3                     1.450000e-08             16400000   \n",
      "4                     1.210000e-08             16400000   \n",
      "\n",
      "   Strain to Deformation Ratio  Length (mm)  Breadth (mm)  Depth (mm)  \n",
      "0                    13.783160        403.1         406.3       101.0  \n",
      "1                    13.776398        399.9         412.5       100.9  \n",
      "2                    13.767023        403.0         412.7        99.5  \n",
      "3                    13.772023        397.8         412.7        99.7  \n",
      "4                    13.830928        398.0         408.9        99.1  \n"
     ]
    }
   ],
   "source": [
    "# Scale the 'Maximum Principal Elastic Strain' column by 10^10\n",
    "df['Maximum Principal Elastic Strain (m/m)'] = df['Maximum Principal Elastic Strain (m/m)'] * 1e10\n",
    "\n",
    "# Optionally, check the updated values\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter space\n",
    "hyp_space  = [\n",
    "    Integer(3, 15, name='num_layers'), # Num of layers in the network (depth)\n",
    "    Integer(50, 300, name='num_units'), # Num of neurons in each hidden layer (width)\n",
    "    Real(0.00001, 0.2, prior='log-uniform', name='learning_rate'), # Steps size at each iteration \n",
    "    Real(0.0, 0.7, name='dropout_rate'), # Probability of droping out a neuron\n",
    "    Integer(20, 200, name='batch_size'), # Num of samples per batch\n",
    "    Integer(50, 250, name='epochs') # Num of epochs (iterations over the entire dataset) during training\n",
    "]\n",
    "\n",
    "# Defining the Neural Network Model\n",
    "def NN_model(num_layers, num_units, learning_rate, dropout_rate):\n",
    "    inputs = Input(shape=(3,))\n",
    "    x = Dense(num_units, activation='relu', kernel_regularizer='l2')(inputs)\n",
    "    for _ in range(num_layers - 1):\n",
    "        x = Dense(num_units, activation='relu', kernel_regularizer='l2')(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Function for MC Dropout predictions\n",
    "def mc_dropout_predictions(model, X, num_samples=50):\n",
    "    predictions = np.zeros((num_samples, X.shape[0]))\n",
    "    for i in range(num_samples):\n",
    "        predictions[i, :] = model(X, training=True).numpy().flatten()\n",
    "    prediction_mean = predictions.mean(axis=0)\n",
    "    prediction_std = predictions.std(axis=0)\n",
    "    return prediction_mean, prediction_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "num_layers: 4\n",
      "num_units: 296\n",
      "learning_rate: 0.038098440670222465\n",
      "dropout_rate: 0.07336707667550668\n",
      "batch_size: 170\n",
      "epochs: 67\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function to minimize\n",
    "@use_named_args(hyp_space)\n",
    "def objective(**params):\n",
    "    num_layers = params['num_layers']\n",
    "    num_units = params['num_units']\n",
    "    learning_rate = params['learning_rate']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "\n",
    "    model = NN_model(num_layers, num_units, learning_rate, dropout_rate)\n",
    "\n",
    "    # Define K-fold cross-validation\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "    scores = []\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_idx, val_idx in kfold.split(df[['Length (mm)', 'Breadth (mm)', 'Depth (mm)']]):\n",
    "        X_train, X_val = df[['Length (mm)', 'Breadth (mm)', 'Depth (mm)']].iloc[train_idx], df[['Length (mm)', 'Breadth (mm)', 'Depth (mm)']].iloc[val_idx]\n",
    "        y_train, y_val = df[['Maximum Principal Elastic Strain (m/m)']].iloc[train_idx], df[['Maximum Principal Elastic Strain (m/m)']].iloc[val_idx]\n",
    "\n",
    "        # Standardize the features\n",
    "        scaler_x = StandardScaler().fit(X_train)\n",
    "        X_train_scaled = scaler_x.transform(X_train)\n",
    "        X_val_scaled = scaler_x.transform(X_val)\n",
    "\n",
    "        # Train the model\n",
    "        # early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=batch_size, verbose=0, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "        # Evaluate the model\n",
    "        score = model.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "result = gp_minimize(objective, hyp_space, n_calls=30, random_state=0, acq_func='EI')\n",
    "\n",
    "# Output best hyperparameters from BayesOpt\n",
    "print(\"Best hyperparameters:\")\n",
    "print(\"num_layers:\", result.x[0])\n",
    "print(\"num_units:\", result.x[1])\n",
    "print(\"learning_rate:\", result.x[2])\n",
    "print(\"dropout_rate:\", result.x[3])\n",
    "print(\"batch_size:\", result.x[4])\n",
    "print(\"epochs:\", result.x[5])\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = NN_model(\n",
    "    num_layers=result.x[0],\n",
    "    num_units=result.x[1],\n",
    "    learning_rate=result.x[2],\n",
    "    dropout_rate=result.x[3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 3538.9084\n",
      "Epoch 2/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 34540.0703\n",
      "Epoch 3/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3367.7156\n",
      "Epoch 4/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3533.7578\n",
      "Epoch 5/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3529.1094\n",
      "Epoch 6/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3517.2681\n",
      "Epoch 7/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3497.8708\n",
      "Epoch 8/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3463.2358\n",
      "Epoch 9/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3414.7422\n",
      "Epoch 10/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3373.0408\n",
      "Epoch 11/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3256.9773\n",
      "Epoch 12/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3056.9055\n",
      "Epoch 13/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2732.3027\n",
      "Epoch 14/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2461.9292\n",
      "Epoch 15/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2613.7598\n",
      "Epoch 16/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2735.1338\n",
      "Epoch 17/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2407.1650\n",
      "Epoch 18/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2182.5286\n",
      "Epoch 19/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2218.2615\n",
      "Epoch 20/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2116.6941\n",
      "Epoch 21/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2010.1438\n",
      "Epoch 22/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1696.7560\n",
      "Epoch 23/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1876.6049\n",
      "Epoch 24/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1808.8121\n",
      "Epoch 25/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1445.5198\n",
      "Epoch 26/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1450.4790\n",
      "Epoch 27/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1259.5619\n",
      "Epoch 28/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1365.7661\n",
      "Epoch 29/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1240.6553\n",
      "Epoch 30/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1236.2213\n",
      "Epoch 31/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1097.0287\n",
      "Epoch 32/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1021.0252\n",
      "Epoch 33/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 963.3270\n",
      "Epoch 34/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 895.5390\n",
      "Epoch 35/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 847.3792\n",
      "Epoch 36/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 896.7490\n",
      "Epoch 37/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 887.2385\n",
      "Epoch 38/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 920.4942\n",
      "Epoch 39/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 829.2529\n",
      "Epoch 40/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 798.7123\n",
      "Epoch 41/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 849.2643\n",
      "Epoch 42/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 865.1400\n",
      "Epoch 43/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 896.4662\n",
      "Epoch 44/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 781.0930\n",
      "Epoch 45/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 884.6160\n",
      "Epoch 46/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 831.1970\n",
      "Epoch 47/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 826.9708\n",
      "Epoch 48/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 807.3675\n",
      "Epoch 49/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 794.1089\n",
      "Epoch 50/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 829.6461\n",
      "Epoch 51/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 726.3546\n",
      "Epoch 52/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 695.6161\n",
      "Epoch 53/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 802.6783\n",
      "Epoch 54/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 846.0948\n",
      "Epoch 55/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 872.0259\n",
      "Epoch 56/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 794.8005\n",
      "Epoch 57/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 787.4942\n",
      "Epoch 58/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 737.0268\n",
      "Epoch 59/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 743.6514\n",
      "Epoch 60/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 765.0797\n",
      "Epoch 61/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 817.9030\n",
      "Epoch 62/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 777.7747\n",
      "Epoch 63/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 755.8857\n",
      "Epoch 64/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 744.0605\n",
      "Epoch 65/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 719.1853\n",
      "Epoch 66/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 851.0610\n",
      "Epoch 67/67\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 771.1097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x210281594f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the initial dataset\n",
    "scaler_x = StandardScaler().fit(df[['Length (mm)', 'Breadth (mm)', 'Depth (mm)']])\n",
    "X_scaled = scaler_x.transform(df[['Length (mm)', 'Breadth (mm)', 'Depth (mm)']])\n",
    "\n",
    "# Train the best model on the initial dataset\n",
    "best_model.fit(X_scaled, df[['Maximum Principal Elastic Strain (m/m)']], epochs=result.x[5], batch_size=result.x[4], verbose=1)\n",
    "\n",
    "# # Produce Meshgrid of results with C.I. \n",
    "# x1_range = np.linspace(360, 470, 100)\n",
    "# x2_range  = np.linspace(360, 470, 100)\n",
    "\n",
    "# x1_grid, x2_grid = np.meshgrid(x1_range, x2_range)\n",
    "# x_grid = np.c_[x1_grid.ravel(), x2_grid.ravel()]\n",
    "\n",
    "# x_grid = scaler_x.transform(x_grid)\n",
    "\n",
    "# # Perform MC Dropout predictions for entire meshgrid\n",
    "# pred_mean, pred_std = mc_dropout_predictions(best_model, x_grid)\n",
    "\n",
    "# # Define range for inputs\n",
    "# bounds = np.array([[360, 470], [360, 470]])\n",
    "\n",
    "# # Identify top 10 points with highest uncertainty\n",
    "# num_new_points = 10\n",
    "\n",
    "# sampler = qmc.LatinHypercube(d=2)  # LHS in a 2D space\n",
    "# lhs_sample = sampler.random(n=1000)\n",
    "# lhs_points = qmc.scale(lhs_sample, bounds[:, 0], bounds[:, 1])\n",
    "\n",
    "# lhs_points_standardized = scaler_x.transform(lhs_points)\n",
    "\n",
    "# lhs_mean, lhs_std = mc_dropout_predictions(best_model, lhs_points_standardized)\n",
    "\n",
    "# percentile_threshold = 90 \n",
    "# threshold_value = np.percentile(lhs_mean, percentile_threshold)\n",
    "\n",
    "# # Filter points above the threshold\n",
    "# points_above_threshold = lhs_points[lhs_mean >= threshold_value]\n",
    "\n",
    "# num_new_points = 10\n",
    "# if len(points_above_threshold) > num_new_points:\n",
    "#     selected_indices = np.random.choice(len(points_above_threshold), num_new_points, replace=False)\n",
    "#     selected_points = points_above_threshold[selected_indices]\n",
    "# else:\n",
    "#     selected_points = points_above_threshold\n",
    "\n",
    "# new_points_df = pd.DataFrame(selected_points, columns=['x','y'])\n",
    "\n",
    "# # Ploting mean predictions and confidence intervals\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# # Reshaping predictions back to grid shape\n",
    "# pred_mean_grid = pred_mean.reshape(x1_grid.shape)\n",
    "# pred_upper_grid = (pred_mean + (1.96 * pred_std)).reshape(x1_grid.shape)\n",
    "# pred_lower_grid = (pred_mean - (1.96 * pred_std)).reshape(x1_grid.shape)\n",
    "\n",
    "# mean_surface = ax.plot_surface(x1_grid, x2_grid, pred_mean_grid, color='blue', alpha=0.5, label='Mean Prediction')\n",
    "# upper_surface = ax.plot_surface(x1_grid, x2_grid, pred_upper_grid, color='red', alpha=0.3, label='Upper Bound (95% CI)')\n",
    "# lower_surface = ax.plot_surface(x1_grid, x2_grid, pred_lower_grid, color='green', alpha=0.3, label='Lower Bound (95% CI)')\n",
    "\n",
    "# # Plot next points for sampling\n",
    "# ax.scatter(selected_points[:, 0], selected_points[:, 1], color='black', marker='o', label='Next Sampling Points')\n",
    "\n",
    "# # Plot Labels\n",
    "# ax.set_title('Neural Network Predictions with Confidence Intervals')\n",
    "# ax.set_xlabel('Length (mm)')\n",
    "# ax.set_ylabel('Breadth (mm)')\n",
    "# ax.set_zlabel('Equivalent Elastic Strain (m/m)')\n",
    "\n",
    "# # Legend\n",
    "# legend_elements = [mean_surface, upper_surface, lower_surface]\n",
    "# fig.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X = df[['Length (mm)', 'Breadth (mm)', 'Depth (mm)']].to_numpy()\n",
    "train_y = df['Maximum Principal Elastic Strain (m/m)'].to_numpy()\n",
    "\n",
    "# Standardize the initial dataset\n",
    "scaler_x = StandardScaler().fit(train_X)\n",
    "X_scaled = scaler_x.transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Mean Squared Error (MSE): 651.1357771449027\n",
      "Mean Absolute Error (MAE): 15.36483154296875\n",
      "R² Score: 0.5019848664673041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_pred = best_model.predict(X_scaled)\n",
    "\n",
    "# # Calculate regression metrics\n",
    "mse = mean_squared_error(train_y, y_pred)\n",
    "mae = mean_absolute_error(train_y, y_pred)\n",
    "r2 = r2_score(train_y, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R² Score: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
