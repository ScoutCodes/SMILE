{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Simon\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "from perlin_numpy import generate_perlin_noise_2d\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "np.random.seed(1)\n",
    "\n",
    "m = 5 # Physical observations per iteration (Default 5)\n",
    "n = 100 # Simulated observations per iteration (Default 100)\n",
    "\n",
    "# Number of observations to train the GP on before starting the active learning loop\n",
    "pretrain_n = 1\n",
    "\n",
    "# Minimum percentile to explore each iteration\n",
    "percentile = 50\n",
    "\n",
    "# Number of iterations to run the active learning loop (Default 10)\n",
    "iterations = 10\n",
    "\n",
    "# Corrective constant when calculating percentages\n",
    "laplace_alpha = 0.01\n",
    "\n",
    "# Degree of the polynomial to fit to the data\n",
    "degree = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bounds for the function\n",
    "xy_range = objectives[obj][\"bounds\"]\n",
    "\n",
    "# Generate the meshgrid for the function\n",
    "X = np.arange(*xy_range[0], ((xy_range[0][1] - xy_range[0][0]) / 100))\n",
    "Y = np.arange(*xy_range[1], ((xy_range[1][1] - xy_range[1][0]) / 100))\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = objectives[obj][\"func\"](X, Y) # Values are computed and stored in Z\n",
    "\n",
    "# Get the range of the function\n",
    "z_range = (np.floor(np.min(Z)) - 1, np.ceil(np.max(Z)) + 1) # Used later in interpolations\n",
    "\n",
    "# Generate the initial training data\n",
    "df = pd.DataFrame(np.random.randint(100, size=(pretrain_n, 2))) \n",
    "\n",
    "# Rename the index columns\n",
    "df.columns = [\"i\", \"j\"]\n",
    "\n",
    "# Calculate the x, y, and z columns with some random error\n",
    "df[\"x\"] = X[0, df[\"i\"]]\n",
    "df[\"y\"] = Y[df[\"j\"], 0]\n",
    "df[\"z\"] = Z[df[\"i\"], df[\"j\"]] + ran_err(pretrain_n, 0.05)\n",
    "\n",
    "# Create a copy of the dataframe to store the simulated data\n",
    "simul_df = df.copy()\n",
    "\n",
    "# Fit a polynomial (model) to the (initial) data\n",
    "poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "poly_features = poly_features.fit_transform(simul_df[[\"x\", \"y\"]])\n",
    "\n",
    "# Fit a linear regression model to polynomial\n",
    "poly_model = LinearRegression()\n",
    "poly_model = poly_model.fit(poly_features, simul_df[\"z\"])\n",
    "\n",
    "# Generate some more initial training data \n",
    "df = pd.DataFrame(np.random.randint(100, size=(m, 2)))\n",
    "\n",
    "# Rename the index columns\n",
    "df.columns = [\"i\", \"j\"]\n",
    "\n",
    "# Calculate the x, y, and z columns with some random error\n",
    "df[\"x\"] = X[0, df[\"i\"]]\n",
    "df[\"y\"] = Y[df[\"j\"], 0]\n",
    "df[\"z\"] = Z[df[\"i\"], df[\"j\"]] + ran_err(m, 0.05)\n",
    "\n",
    "# Active learning loop\n",
    "#Purpose: Iteratively improve the GP model by sampling new points based on model's predictions\n",
    "for idx in range(1, iterations + 1):\n",
    "    # Fit a Gaussian Process to the data\n",
    "    krnl = RBF(length_scale=1) # Radial Basis Function (used for smoothness and variability of the functions that GP can model)\n",
    "    model = GaussianProcessRegressor(kernel=krnl, normalize_y=False, random_state=3, alpha=0.001) # target values are not normalized, reproducibility is ensured, noise level to omprove stability in predictions. \n",
    "\n",
    "    # Randomly sample within our function's bounds\n",
    "    tmp_df = pd.DataFrame(np.random.randint(100, size=(n, 2)))\n",
    "\n",
    "    # Rename the index columns\n",
    "    tmp_df.columns = [\"i\", \"j\"]\n",
    "\n",
    "    # Generate some simulated data (using the poly model with some systematic error)\n",
    "    tmp_df[\"x\"] = X[0, tmp_df[\"i\"]]\n",
    "    tmp_df[\"y\"] = Y[tmp_df[\"j\"], 0]\n",
    "    tmp_df[\"z\"] = sys_err(n, tmp_df[\"x\"], tmp_df[\"y\"], poly_model)\n",
    "\n",
    "    # Fit a GP to the data\n",
    "    model.fit(tmp_df[[\"x\", \"y\"]], tmp_df[\"z\"])\n",
    "\n",
    "    # Make predictions using simulated data\n",
    "    pred = model.predict(tmp_df[[\"x\", \"y\"]])\n",
    "\n",
    "    # Interpolate the predictions to the meshgrid\n",
    "    z = griddata((tmp_df[\"x\"], tmp_df[\"y\"]), pred, (X.T, Y.T), method=\"linear\", fill_value=z_range[0])\n",
    "\n",
    "    # Construct a grid of all points in the meshgrid\n",
    "    tmp_df = pd.DataFrame(list(product(range(100), range(100))), columns=[\"i\", \"j\"])\n",
    "\n",
    "    # Calculate the x, y, and z columns with some random error\n",
    "    tmp_df[\"x\"] = X[0, tmp_df[\"i\"]]\n",
    "    tmp_df[\"y\"] = Y[tmp_df[\"j\"], 0]\n",
    "    tmp_df[\"z\"] = Z[tmp_df[\"i\"], tmp_df[\"j\"]] + ran_err(10000, 0.05) # Actual function values with some random error are calculated for full grid\n",
    "\n",
    "    # Construct probability distribution for points to sample from\n",
    "    mag = z[tmp_df[\"i\"], tmp_df[\"j\"]] # Computed mag for grid points\n",
    "    p = mag - z.min()\n",
    "    p = np.where(p > np.percentile(p, percentile), p, 0) + laplace_alpha \n",
    "    p /= p.sum()\n",
    "    tmp_df = tmp_df.loc[np.random.choice(tmp_df.index, size=m, p=p, replace=False)]\n",
    "\n",
    "    # Training Data is updated to include new sampled points \n",
    "    df = pd.concat([df, tmp_df], ignore_index=True)\n",
    "\n",
    "    simul_df = pd.concat([simul_df, tmp_df], ignore_index=True)\n",
    "\n",
    "    # Refitted Polynomial Model using updated data\n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    poly_features = poly_features.fit_transform(simul_df[[\"x\", \"y\"]])\n",
    "\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model = poly_model.fit(poly_features, simul_df[\"z\"])\n",
    "\n",
    "# GP model is refitted on the complete dataset\n",
    "krnl = RBF(length_scale=1)\n",
    "model = GaussianProcessRegressor(kernel=krnl, normalize_y=False, random_state=3, alpha=0.001)\n",
    "\n",
    "model.fit(df[[\"x\", \"y\"]], df[\"z\"])\n",
    "\n",
    "# Prediction for entire dataset \n",
    "pred = model.predict(df[[\"x\", \"y\"]])\n",
    "\n",
    "# Interpolate predictions on meshgrid\n",
    "z = griddata((df[\"x\"], df[\"y\"]), pred, (X.T, Y.T), method=\"linear\", fill_value=(z_range[0] + 1))\n",
    "\n",
    "# Performance is printed as the percentile score of the maximum prediction compared to the actual function values\n",
    "print(obj, percentileofscore(Z.flatten(), Z[np.unravel_index(z.argmax(), z.shape)]), sep=\"\\t\", end=\"\\r\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
