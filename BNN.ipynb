{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective Function (Black Box Function)\n",
    "def target_func(x, y): \n",
    "    return  -(20 * (1 - np.exp(-0.2 * np.sqrt(0.5 * (x**2 + y**2)))) - np.exp(0.5 * (np.cos(2 * np.pi * x) + np.cos(2 * np. pi * y))) + np.exp(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamter Space for inputs x and y\n",
    "space = [\n",
    "    Real(-35, 35, name='x'),\n",
    "    Real(-35, 35, name='y')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "x: 33.520674796205455\n",
      "y: 18.528723000152247\n",
      "Minimum value of the objective function: -22.25698796416003\n"
     ]
    }
   ],
   "source": [
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    x = params['x']\n",
    "    y = params['y']\n",
    "    z = target_func(x, y)\n",
    "    return z\n",
    "\n",
    "# Bayesian Optimization\n",
    "result = gp_minimize(objective, space, n_calls=50, random_state=0)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found:\")\n",
    "print(\"x:\", result.x[0])\n",
    "print(\"y:\", result.x[1])\n",
    "\n",
    "# Print the minimum value of the objective function\n",
    "print(\"Minimum value of the objective function:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Model for Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the true objective function z = f(x, y)\n",
    "def obj_func(x, y):\n",
    "    return -(20 * (1 - np.exp(-0.2 * np.sqrt(0.5 * (x**2 + y**2)))) - np.exp(0.5 * (np.cos(2 * np.pi * x) + np.cos(2 * np. pi * y))) + np.exp(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate synthetic data for training the neural network\n",
    "def generate_data():\n",
    "    x = np.random.uniform(-35, 35, 1000)\n",
    "    y = np.random.uniform(-35, 35, 1000)\n",
    "    z = obj_func(x, y)\n",
    "    return np.vstack((x, y)).T, z\n",
    "\n",
    "# Generate the data\n",
    "X, z = generate_data()\n",
    "\n",
    "# Preprocess the data \n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# Define the hyperparameter space\n",
    "hyp_space  = [\n",
    "    Integer(1, 5, name='num_layers'), # Num of layers in the network (depth)\n",
    "    Integer(10, 100, name='num_units'), # Num of neurons in each hidden layer (width)\n",
    "    Real(0.0001, 0.1, prior='log-uniform', name='learning_rate'), # Steps size at each iteration \n",
    "    Real(0.0, 0.5, name='dropout_rate'), # Probability of droping out a neuron\n",
    "    Integer(10, 100, name='batch_size'), # Num of samples per batch\n",
    "    Integer(1, 20, name='epochs') # Num of epochs (iterations over the entire dataset) during training\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "num_layers: 5\n",
      "num_units: 100\n",
      "learning_rate: 0.0031278782792757273\n",
      "dropout_rate: 0.0\n",
      "batch_size: 10\n",
      "epochs: 17\n"
     ]
    }
   ],
   "source": [
    "# Defining the neural network model\n",
    "def NN_model(num_layers, num_units, learning_rate, dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_units, activation='relu', input_shape=(2,)))\n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Define the objective function to minimize\n",
    "@use_named_args(hyp_space)\n",
    "def objective(**params):\n",
    "    model = KerasRegressor(model=NN_model, **params, verbose=0)\n",
    "    return -np.mean(cross_val_score(model, X, z, cv=3, n_jobs=-1, scoring='neg_mean_squared_error'))\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "result = gp_minimize(objective, hyp_space, n_calls=50, random_state=0, acq_func='EI')\n",
    "\n",
    "# Outpu best hyperparameters from BayesOpt\n",
    "print(\"Best hyperparameters:\")\n",
    "print(\"num_layers:\", result.x[0])\n",
    "print(\"num_units:\", result.x[1])\n",
    "print(\"learning_rate:\", result.x[2])\n",
    "print(\"dropout_rate:\", result.x[3])\n",
    "print(\"batch_size:\", result.x[4])\n",
    "print(\"epochs:\", result.x[5])\n",
    "\n",
    "# Train the model with the best hyperparameters on the entire dataset\n",
    "best_model = KerasRegressor(\n",
    "    model=NN_model,\n",
    "    num_layers=result.x[0],\n",
    "    num_units=result.x[1],\n",
    "    learning_rate=result.x[2],\n",
    "    dropout_rate=result.x[3],\n",
    "    batch_size=result.x[4],\n",
    "    epochs=result.x[5],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Simon\\anaconda3\\envs\\research\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - loss: 110.6410\n",
      "Epoch 2/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 24.4244\n",
      "Epoch 3/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 18.9009\n",
      "Epoch 4/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 8.8059\n",
      "Epoch 5/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 4.7949\n",
      "Epoch 6/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 2.0004\n",
      "Epoch 7/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 2.4699\n",
      "Epoch 8/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 2.1378\n",
      "Epoch 9/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 1.5223\n",
      "Epoch 10/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 1.1802\n",
      "Epoch 11/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 1.0605\n",
      "Epoch 12/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.6725\n",
      "Epoch 13/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.7699\n",
      "Epoch 14/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.6793\n",
      "Epoch 15/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.6658\n",
      "Epoch 16/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.4513\n",
      "Epoch 17/17\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.5391\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step\n",
      "Model MSE: 0.9069652483098025\n"
     ]
    }
   ],
   "source": [
    "# Spliting data into training and testing sets\n",
    "X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train best model\n",
    "best_model.fit(X_train, z_train)\n",
    "\n",
    "# Evaluate best model\n",
    "mse = best_model.score(X_test, z_test)\n",
    "print(\"Model MSE:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
